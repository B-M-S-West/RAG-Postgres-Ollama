# RAG-Postgres-Ollama

A full-stack Retrieval-Augmented Generation (RAG) system for document ingestion, semantic search, and question answering, powered by FastAPI, Streamlit, PostgreSQL (with pgvector), Ollama for embeddings and LLMs, and Docling for document parsing.

---

## Features

- **Document Upload & Processing**: Upload PDFs, DOCX, TXT, HTML, and more. Documents are parsed (via Docling), chunked, embedded, and stored.
- **Semantic Search**: Search across all documents using natural language queries.
- **RAG Q&A**: Ask questions and get answers generated by an LLM, with cited sources from your document collection.
- **Analytics Dashboard**: Visualize document stats, types, and system health.
- **Document Library**: Browse, preview, and manage uploaded documents.
- **Chunking Strategies**: Supports semantic, fixed-size, sentence, paragraph, and recursive chunking.
- **Embeddings & LLMs**: Uses Ollama for both embedding generation and answer synthesis.
- **Cloud Storage**: Supports MinIO/S3 for file storage.
- **Extensible**: Modular codebase for easy extension and customization.

---

## Architecture

```
[Streamlit Frontend] <--REST--> [FastAPI Backend] <---> [PostgreSQL + pgvector]
                                               |
                                               +---> [Ollama (Embeddings & LLM)]
                                               +---> [Docling (Document Parsing)]
                                               +---> [MinIO/S3 (File Storage)]
```

---

## Quickstart

### 1. Prerequisites

- Python 3.12+
- PostgreSQL with [pgvector](https://github.com/pgvector/pgvector) extension
- [Ollama](https://ollama.com/) running locally (for embeddings and LLM)
- [Docling](https://github.com/docling-ai/docling) server running locally
- (Optional) [MinIO](https://min.io/) or S3-compatible storage for file uploads

### 2. Install Python Dependencies

```bash
python3.12 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
Or if using uv
```bash
python3.12 -m venv .venv
source .venv/bin/activate
uv pip install -r requirements.txt
```


### 3. Environment Variables

Create a `.env` file in the project root with the following (adjust as needed):

```
# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=vector_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=yourpassword

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text:latest

# Docling
DOCLING_URL=http://localhost:5002

# MinIO/S3 (optional)
MINIO_ENDPOINT=http://localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=rag-docs
MINIO_SECURE=false
DOCKER_MINIO_ENDPOINT=http://localhost:9000
```

### 4. Start Services

#### Start PostgreSQL with pgvector

Install the [pgvector extension](https://github.com/pgvector/pgvector) and create your database.

#### Start Ollama

```bash
ollama serve
# Pull required models:
ollama pull nomic-embed-text:latest
ollama pull gemma3:1b-it-qat
```

#### Start Docling

Follow [Docling's instructions](https://github.com/docling-ai/docling) to run the server.

#### (Optional) Start MinIO

```bash
docker run -p 9000:9000 -p 9001:9001 --name minio \
  -e "MINIO_ROOT_USER=minioadmin" -e "MINIO_ROOT_PASSWORD=minioadmin" \
  quay.io/minio/minio server /data --console-address ":9001"
```

---

### 5. Run the Backend

```bash
uv run fastapi dev --port 8001
```

### 6. Run the Frontend

```bash
streamlit run app/frontend.py
```

---

## Usage

- **Upload Documents**: Use the "Upload Documents" page in the Streamlit UI.
- **Search & Query**: Use natural language to search or ask questions.
- **Analytics**: View document and system stats.
- **Document Library**: Browse, preview, and delete documents.

---

## Project Structure

```
app/
  api/           # FastAPI routes
  db/            # Database (PostgreSQL/pgvector) logic
  rag/           # RAG pipeline: chunking, embedding, retrieval, storage
  utils/         # Logging and utilities
  models.py      # Pydantic models
  main.py        # FastAPI app entrypoint
  frontend.py    # Streamlit UI
```

---

## Development

- Logging is configured to both console and `logs/`.
- All major components are modular and can be extended.
- See `pyproject.toml` for dependencies.

---

## Troubleshooting

- **Ollama not running**: Ensure `ollama serve` is active and models are pulled.
- **Docling errors**: Check Docling server logs and ensure file URLs are accessible.
- **Database errors**: Ensure PostgreSQL is running and `pgvector` is installed.
- **MinIO/S3 issues**: Check credentials and bucket configuration.

---

## Credits

- [Ollama](https://ollama.com/)
- [Docling](https://github.com/docling-ai/docling)
- [pgvector](https://github.com/pgvector/pgvector)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://streamlit.io/)

---

## TODO

- Add Docker Compose for full stack deployment
- Add authentication and user management
- Improve error handling and monitoring
- Add more chunking and embedding strategies

---